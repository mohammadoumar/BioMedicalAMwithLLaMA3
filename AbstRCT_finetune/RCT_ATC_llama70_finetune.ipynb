{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1oHFCsV0z-Jw"
   },
   "source": [
    "# Finetune LLaMA-3 on AbstRCT dataset for ATC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lr7rB3szzhtx"
   },
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "giM74oK1rRIH",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: git: command not found\n",
      "/nfs/scratch/umushtaq/am_work/LLaMA-Factory\n",
      "CITATION.cff  Makefile      \u001b[0m\u001b[01;34massets\u001b[0m/  \u001b[01;34mevaluation\u001b[0m/     requirements.txt  \u001b[01;34msrc\u001b[0m/\n",
      "LICENSE       README.md     \u001b[01;34mdata\u001b[0m/    \u001b[01;34mexamples\u001b[0m/       \u001b[01;34mscripts\u001b[0m/          \u001b[01;34mtests\u001b[0m/\n",
      "MANIFEST.in   README_zh.md  \u001b[01;34mdocker\u001b[0m/  pyproject.toml  setup.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///nfs/scratch/umushtaq/am_work/LLaMA-Factory\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: transformers>=4.41.2 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from llamafactory==0.8.3.dev0) (4.42.3)\n",
      "Requirement already satisfied: datasets>=2.16.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from llamafactory==0.8.3.dev0) (2.20.0)\n",
      "Requirement already satisfied: accelerate>=0.30.1 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from llamafactory==0.8.3.dev0) (0.31.0)\n",
      "Requirement already satisfied: peft>=0.11.1 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from llamafactory==0.8.3.dev0) (0.11.1)\n",
      "Requirement already satisfied: trl>=0.8.6 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from llamafactory==0.8.3.dev0) (0.9.4)\n",
      "Collecting gradio>=4.0.0 (from llamafactory==0.8.3.dev0)\n",
      "  Using cached gradio-4.37.2-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: pandas>=2.0.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from llamafactory==0.8.3.dev0) (2.2.2)\n",
      "Requirement already satisfied: scipy in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from llamafactory==0.8.3.dev0) (1.14.0)\n",
      "Requirement already satisfied: einops in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from llamafactory==0.8.3.dev0) (0.8.0)\n",
      "Requirement already satisfied: sentencepiece in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from llamafactory==0.8.3.dev0) (0.2.0)\n",
      "Requirement already satisfied: tiktoken in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from llamafactory==0.8.3.dev0) (0.7.0)\n",
      "Requirement already satisfied: protobuf in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from llamafactory==0.8.3.dev0) (5.27.2)\n",
      "Requirement already satisfied: uvicorn in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from llamafactory==0.8.3.dev0) (0.30.1)\n",
      "Requirement already satisfied: pydantic in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from llamafactory==0.8.3.dev0) (1.10.9)\n",
      "Requirement already satisfied: fastapi in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from llamafactory==0.8.3.dev0) (0.111.0)\n",
      "Requirement already satisfied: sse-starlette in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from llamafactory==0.8.3.dev0) (2.1.2)\n",
      "Requirement already satisfied: matplotlib>=3.7.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from llamafactory==0.8.3.dev0) (3.9.0)\n",
      "Requirement already satisfied: fire in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from llamafactory==0.8.3.dev0) (0.6.0)\n",
      "Requirement already satisfied: packaging in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from llamafactory==0.8.3.dev0) (24.1)\n",
      "Requirement already satisfied: pyyaml in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from llamafactory==0.8.3.dev0) (6.0.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from llamafactory==0.8.3.dev0) (1.26.4)\n",
      "Requirement already satisfied: bitsandbytes>=0.39.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from llamafactory==0.8.3.dev0) (0.43.1)\n",
      "Requirement already satisfied: torch>=1.13.1 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from llamafactory==0.8.3.dev0) (2.3.1)\n",
      "Requirement already satisfied: psutil in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from accelerate>=0.30.1->llamafactory==0.8.3.dev0) (6.0.0)\n",
      "Requirement already satisfied: huggingface-hub in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from accelerate>=0.30.1->llamafactory==0.8.3.dev0) (0.23.4)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from accelerate>=0.30.1->llamafactory==0.8.3.dev0) (0.4.3)\n",
      "Requirement already satisfied: filelock in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from datasets>=2.16.0->llamafactory==0.8.3.dev0) (3.15.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from datasets>=2.16.0->llamafactory==0.8.3.dev0) (16.1.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from datasets>=2.16.0->llamafactory==0.8.3.dev0) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from datasets>=2.16.0->llamafactory==0.8.3.dev0) (0.3.8)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from datasets>=2.16.0->llamafactory==0.8.3.dev0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from datasets>=2.16.0->llamafactory==0.8.3.dev0) (4.66.4)\n",
      "Requirement already satisfied: xxhash in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from datasets>=2.16.0->llamafactory==0.8.3.dev0) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from datasets>=2.16.0->llamafactory==0.8.3.dev0) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets>=2.16.0->llamafactory==0.8.3.dev0) (2024.5.0)\n",
      "Requirement already satisfied: aiohttp in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from datasets>=2.16.0->llamafactory==0.8.3.dev0) (3.9.5)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (23.2.1)\n",
      "Requirement already satisfied: altair<6.0,>=4.2.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (5.3.0)\n",
      "Requirement already satisfied: ffmpy in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (0.3.2)\n",
      "Collecting gradio-client==1.0.2 (from gradio>=4.0.0->llamafactory==0.8.3.dev0)\n",
      "  Using cached gradio_client-1.0.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (0.27.0)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (6.4.0)\n",
      "Requirement already satisfied: jinja2<4.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (3.1.4)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (2.1.5)\n",
      "Requirement already satisfied: orjson~=3.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (3.10.5)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (10.3.0)\n",
      "Collecting pydantic (from llamafactory==0.8.3.dev0)\n",
      "  Downloading pydantic-2.8.2-py3-none-any.whl.metadata (125 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pydub in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (0.0.9)\n",
      "Requirement already satisfied: ruff>=0.2.2 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (0.5.0)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (2.10.0)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (0.12.0)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (0.12.3)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (4.12.2)\n",
      "Requirement already satisfied: urllib3~=2.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (2.2.2)\n",
      "Requirement already satisfied: websockets<12.0,>=10.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from gradio-client==1.0.2->gradio>=4.0.0->llamafactory==0.8.3.dev0) (11.0.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from matplotlib>=3.7.0->llamafactory==0.8.3.dev0) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from matplotlib>=3.7.0->llamafactory==0.8.3.dev0) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from matplotlib>=3.7.0->llamafactory==0.8.3.dev0) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from matplotlib>=3.7.0->llamafactory==0.8.3.dev0) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from matplotlib>=3.7.0->llamafactory==0.8.3.dev0) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from matplotlib>=3.7.0->llamafactory==0.8.3.dev0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from pandas>=2.0.0->llamafactory==0.8.3.dev0) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from pandas>=2.0.0->llamafactory==0.8.3.dev0) (2024.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from pydantic->llamafactory==0.8.3.dev0) (0.7.0)\n",
      "Collecting pydantic-core==2.20.1 (from pydantic->llamafactory==0.8.3.dev0)\n",
      "  Downloading pydantic_core-2.20.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: sympy in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from torch>=1.13.1->llamafactory==0.8.3.dev0) (1.12.1)\n",
      "Requirement already satisfied: networkx in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from torch>=1.13.1->llamafactory==0.8.3.dev0) (3.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from torch>=1.13.1->llamafactory==0.8.3.dev0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from torch>=1.13.1->llamafactory==0.8.3.dev0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from torch>=1.13.1->llamafactory==0.8.3.dev0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from torch>=1.13.1->llamafactory==0.8.3.dev0) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from torch>=1.13.1->llamafactory==0.8.3.dev0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from torch>=1.13.1->llamafactory==0.8.3.dev0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from torch>=1.13.1->llamafactory==0.8.3.dev0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from torch>=1.13.1->llamafactory==0.8.3.dev0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from torch>=1.13.1->llamafactory==0.8.3.dev0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from torch>=1.13.1->llamafactory==0.8.3.dev0) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from torch>=1.13.1->llamafactory==0.8.3.dev0) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.1 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from torch>=1.13.1->llamafactory==0.8.3.dev0) (2.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.1->llamafactory==0.8.3.dev0) (12.5.40)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from transformers>=4.41.2->llamafactory==0.8.3.dev0) (2024.5.15)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from transformers>=4.41.2->llamafactory==0.8.3.dev0) (0.19.1)\n",
      "Requirement already satisfied: tyro>=0.5.11 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from trl>=0.8.6->llamafactory==0.8.3.dev0) (0.8.5)\n",
      "Requirement already satisfied: click>=7.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from uvicorn->llamafactory==0.8.3.dev0) (8.1.7)\n",
      "Requirement already satisfied: h11>=0.8 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from uvicorn->llamafactory==0.8.3.dev0) (0.14.0)\n",
      "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from fastapi->llamafactory==0.8.3.dev0) (0.37.2)\n",
      "Requirement already satisfied: fastapi-cli>=0.0.2 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from fastapi->llamafactory==0.8.3.dev0) (0.0.4)\n",
      "Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from fastapi->llamafactory==0.8.3.dev0) (5.10.0)\n",
      "Requirement already satisfied: email_validator>=2.0.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from fastapi->llamafactory==0.8.3.dev0) (2.2.0)\n",
      "Requirement already satisfied: six in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from fire->llamafactory==0.8.3.dev0) (1.16.0)\n",
      "Requirement already satisfied: termcolor in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from fire->llamafactory==0.8.3.dev0) (2.4.0)\n",
      "Requirement already satisfied: anyio in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from sse-starlette->llamafactory==0.8.3.dev0) (4.4.0)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from altair<6.0,>=4.2.0->gradio>=4.0.0->llamafactory==0.8.3.dev0) (4.22.0)\n",
      "Requirement already satisfied: toolz in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from altair<6.0,>=4.2.0->gradio>=4.0.0->llamafactory==0.8.3.dev0) (0.12.1)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from email_validator>=2.0.0->fastapi->llamafactory==0.8.3.dev0) (2.6.1)\n",
      "Requirement already satisfied: idna>=2.0.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from email_validator>=2.0.0->fastapi->llamafactory==0.8.3.dev0) (3.7)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from aiohttp->datasets>=2.16.0->llamafactory==0.8.3.dev0) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from aiohttp->datasets>=2.16.0->llamafactory==0.8.3.dev0) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from aiohttp->datasets>=2.16.0->llamafactory==0.8.3.dev0) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from aiohttp->datasets>=2.16.0->llamafactory==0.8.3.dev0) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from aiohttp->datasets>=2.16.0->llamafactory==0.8.3.dev0) (1.9.4)\n",
      "Requirement already satisfied: certifi in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from httpx>=0.24.1->gradio>=4.0.0->llamafactory==0.8.3.dev0) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from httpx>=0.24.1->gradio>=4.0.0->llamafactory==0.8.3.dev0) (1.0.5)\n",
      "Requirement already satisfied: sniffio in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from httpx>=0.24.1->gradio>=4.0.0->llamafactory==0.8.3.dev0) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=2.16.0->llamafactory==0.8.3.dev0) (3.3.2)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.8.3.dev0) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.8.3.dev0) (13.7.1)\n",
      "Requirement already satisfied: docstring-parser>=0.16 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from tyro>=0.5.11->trl>=0.8.6->llamafactory==0.8.3.dev0) (0.16)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from tyro>=0.5.11->trl>=0.8.6->llamafactory==0.8.3.dev0) (1.7.1)\n",
      "Requirement already satisfied: httptools>=0.5.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from uvicorn[standard]>=0.12.0->fastapi->llamafactory==0.8.3.dev0) (0.6.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from uvicorn[standard]>=0.12.0->fastapi->llamafactory==0.8.3.dev0) (1.0.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from uvicorn[standard]>=0.12.0->fastapi->llamafactory==0.8.3.dev0) (0.19.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from uvicorn[standard]>=0.12.0->fastapi->llamafactory==0.8.3.dev0) (0.22.0)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from sympy->torch>=1.13.1->llamafactory==0.8.3.dev0) (1.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio>=4.0.0->llamafactory==0.8.3.dev0) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio>=4.0.0->llamafactory==0.8.3.dev0) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio>=4.0.0->llamafactory==0.8.3.dev0) (0.18.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.8.3.dev0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.8.3.dev0) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.8.3.dev0) (0.1.2)\n",
      "Using cached gradio-4.37.2-py3-none-any.whl (12.3 MB)\n",
      "Using cached gradio_client-1.0.2-py3-none-any.whl (318 kB)\n",
      "Downloading pydantic-2.8.2-py3-none-any.whl (423 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m423.9/423.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.20.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hChecking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: llamafactory\n",
      "  Building editable for llamafactory (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for llamafactory: filename=llamafactory-0.8.3.dev0-0.editable-py3-none-any.whl size=20585 sha256=8468e9164010e669711aff1e1ea6dabb1d4a37f6e3067579db9a1d592aabfca9\n",
      "  Stored in directory: /tmp/SLURM_JOB_18516/pip-ephem-wheel-cache-8gds0mnu/wheels/03/52/fa/9133d831955343a17698f9b3e7d5576aaf35f09344adf198ba\n",
      "Successfully built llamafactory\n",
      "Installing collected packages: pydantic-core, pydantic, gradio-client, gradio, llamafactory\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic_core 2.20.0\n",
      "    Uninstalling pydantic_core-2.20.0:\n",
      "      Successfully uninstalled pydantic_core-2.20.0\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 1.10.9\n",
      "    Uninstalling pydantic-1.10.9:\n",
      "      Successfully uninstalled pydantic-1.10.9\n",
      "  Attempting uninstall: gradio-client\n",
      "    Found existing installation: gradio_client 0.6.1\n",
      "    Uninstalling gradio_client-0.6.1:\n",
      "      Successfully uninstalled gradio_client-0.6.1\n",
      "  Attempting uninstall: gradio\n",
      "    Found existing installation: gradio 3.48.0\n",
      "    Uninstalling gradio-3.48.0:\n",
      "      Successfully uninstalled gradio-3.48.0\n",
      "  Attempting uninstall: llamafactory\n",
      "    Found existing installation: llamafactory 0.8.3.dev0\n",
      "    Uninstalling llamafactory-0.8.3.dev0:\n",
      "      Successfully uninstalled llamafactory-0.8.3.dev0\n",
      "Successfully installed gradio-4.37.2 gradio-client-1.0.2 llamafactory-0.8.3.dev0 pydantic-2.8.2 pydantic-core-2.20.1\n"
     ]
    }
   ],
   "source": [
    "# %cd ..\n",
    "# %rm -rf LLaMA-Factory\n",
    "# !git clone https://github.com/hiyouga/LLaMA-Factory.git\n",
    "# %cd ../LLaMA-Factory\n",
    "# %ls\n",
    "# !pip install -e .[torch,bitsandbytes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip uninstall -y pydantic\n",
    "# !pip install pydantic==1.10.9 # \n",
    "\n",
    "# !pip uninstall -y gradio\n",
    "# !pip install gradio==3.48.0\n",
    "\n",
    "# !pip uninstall -y bitsandbytes\n",
    "# !pip install --upgrade bitsandbytes\n",
    "\n",
    "# !pip install tqdm\n",
    "# !pip install ipywidgets\n",
    "# !pip install scikit-learn\n",
    "\n",
    "# Restart kernel afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jul  5 16:16:54 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA H100 PCIe               Off |   00000000:82:00.0 Off |                    0 |\n",
      "| N/A   60C    P0             94W /  350W |       1MiB /  81559MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA H100 PCIe               Off |   00000000:E3:00.0 Off |                    0 |\n",
      "| N/A   66C    P0            107W /  350W |       1MiB /  81559MiB |      3%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import json\n",
    "import torch\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from llamafactory.chat import ChatModel\n",
    "from llamafactory.extras.misc import torch_gc\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/nfs/scratch/umushtaq/am_work/notebooks'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:    \n",
    "    assert torch.cuda.is_available() is True\n",
    "    \n",
    "except AssertionError:\n",
    "    \n",
    "    print(\"Please set up a GPU before using LLaMA Factory...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TeYs5Lz-QJYk"
   },
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/nfs/scratch/umushtaq/am_work/notebooks'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** MODEL NAME ***\n",
    "\n",
    "base_model = \"unsloth/llama-3-70b-bnb-4bit\"\n",
    "\n",
    "# with open(\"tmp.pkl\", \"rb\") as fh:\n",
    "        \n",
    "#         l = pickle.load(fh)\n",
    "#         base_model = l[0]\n",
    "#         train_dataset_name = l[1]\n",
    "#         test_dataset_name = l[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "dataset_dir = os.path.join(parent_dir, \"datasets\")\n",
    "\n",
    "# *** TRAIN DATASET NAME *** #\n",
    "\n",
    "train_dataset_name = \"PE_ATC_essay_train.json\"\n",
    "train_dataset_file = os.path.join(dataset_dir, train_dataset_name)\n",
    "\n",
    "# *** TEST DATASET NAME *** #\n",
    "\n",
    "test_dataset_name = \"PE_ATC_essay_test.json\"\n",
    "test_dataset_file = os.path.join(dataset_dir, test_dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unsloth/llama-3-8b-Instruct-bnb-4bit PE_ATC_essay_train.json PE_ATC_essay_test.json /nfs/scratch/umushtaq/am_work/datasets/PE_ATC_essay_train.json /nfs/scratch/umushtaq/am_work/datasets/PE_ATC_essay_test.json\n"
     ]
    }
   ],
   "source": [
    "print(base_model, train_dataset_name, test_dataset_name, train_dataset_file, test_dataset_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rgR3UFhB0Ifq"
   },
   "source": [
    "## Fine-tune Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# *** MODEL DIR ***\n",
    "model_name = f\"\"\"{train_dataset_name.split(\".\")[0].split(\"train\")[0]}{base_model.split(\"/\")[1]}\"\"\"\n",
    "\n",
    "train_file = os.path.join(parent_dir, f\"\"\"train_file_args/{train_dataset_name.split(\".\")[0].split(\"train\")[0]}{base_model.split(\"/\")[1]}.json\"\"\")\n",
    "output_dir = os.path.join(parent_dir, \"models\", model_name)\n",
    "\n",
    "nb_epochs = 50 # 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new dirs for output and train file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PE_ATC_essay_llama-3-8b-Instruct-bnb-4bit'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/nfs/scratch/umushtaq/am_work/train_file_args/PE_ATC_essay_llama-3-8b-Instruct-bnb-4bit.json'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/nfs/scratch/umushtaq/am_work/models/PE_ATC_essay_llama-3-8b-Instruct-bnb-4bit'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_info_line =  {\n",
    "  \"file_name\": f\"{train_dataset_file}\",\n",
    "  \"columns\": {\n",
    "    \"prompt\": \"instruction\",\n",
    "    \"query\": \"input\",\n",
    "    \"response\": \"output\"\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_name': '/nfs/scratch/umushtaq/am_work/datasets/PE_ATC_essay_train.json',\n",
       " 'columns': {'prompt': 'instruction', 'query': 'input', 'response': 'output'}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_info_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/nfs/scratch/umushtaq/am_work/notebooks'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(parent_dir, \"LLaMA-Factory/data/dataset_info.json\"), \"r\") as jsonFile:\n",
    "    data = json.load(jsonFile)\n",
    "\n",
    "data[\"persuasive_essays\"] = dataset_info_line\n",
    "\n",
    "with open(os.path.join(parent_dir, \"LLaMA-Factory/data/dataset_info.json\"), \"w\") as jsonFile:\n",
    "    json.dump(data, jsonFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "CS0Qk5OR0i4Q",
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = dict(\n",
    "  stage=\"sft\",                           # do supervised fine-tuning\n",
    "  do_train=True,\n",
    "  model_name_or_path=base_model, # use bnb-4bit-quantized Llama-3-8B-Instruct model\n",
    "  cache_dir=\"/blabla\",\n",
    "  # dataset=\"persuasive_essays\",           # use alpaca and identity datasets\n",
    "  dataset=\"persuasive_essays\",           # use alpaca and identity datasets\n",
    "  template=\"llama3\",                     # use llama3 prompt template\n",
    "  finetuning_type=\"lora\",                # use LoRA adapters to save memory\n",
    "  lora_target=\"all\",                     # attach LoRA adapters to all linear layers\n",
    "  output_dir=output_dir,                 # the path to save LoRA adapters\n",
    "  overwrite_output_dir=True,             # overrides existing output contents\n",
    "  per_device_train_batch_size=2,         # the batch size\n",
    "  gradient_accumulation_steps=4,         # the gradient accumulation steps\n",
    "  lr_scheduler_type=\"cosine\",            # use cosine learning rate scheduler\n",
    "  logging_steps=10,                      # log every 10 steps\n",
    "  warmup_ratio=0.1,                      # use warmup scheduler\n",
    "  save_steps=3000,                       # save checkpoint every 1000 steps\n",
    "  learning_rate=5e-5,                    # the learning rate\n",
    "  num_train_epochs=nb_epochs,            # the epochs of training\n",
    "  max_samples=2000,                       # use 500 examples in each dataset\n",
    "  max_grad_norm=1.0,                     # clip gradient norm to 1.0\n",
    "  quantization_bit=4,                    # use 4-bit QLoRA\n",
    "  loraplus_lr_ratio=16.0,                # use LoRA+ algorithm with lambda=16.0\n",
    "  fp16=True,                             # use float16 mixed precision training\n",
    "  report_to=\"none\"                       # discards wandb\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "json.dump(args, open(train_file, \"w\", encoding=\"utf-8\"), indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/nfs/scratch/umushtaq/am_work/notebooks'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nfs/scratch/umushtaq/am_work/LLaMA-Factory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd ../LLaMA-Factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!set train_file = train_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/nfs/scratch/umushtaq/am_work/train_file_args/PE_ATC_essay_llama-3-8b-Instruct-bnb-4bit.json'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/02/2024 18:35:40 - INFO - llamafactory.cli - Initializing distributed tasks at: 127.0.0.1:24436\n",
      "W0702 18:35:41.324000 140183078822400 torch/distributed/run.py:757] \n",
      "W0702 18:35:41.324000 140183078822400 torch/distributed/run.py:757] *****************************************\n",
      "W0702 18:35:41.324000 140183078822400 torch/distributed/run.py:757] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0702 18:35:41.324000 140183078822400 torch/distributed/run.py:757] *****************************************\n",
      "07/02/2024 18:35:48 - WARNING - llamafactory.hparams.parser - We recommend enable `upcast_layernorm` in quantized training.\n",
      "07/02/2024 18:35:48 - WARNING - llamafactory.hparams.parser - `ddp_find_unused_parameters` needs to be set as False for LoRA in DDP training.\n",
      "07/02/2024 18:35:48 - INFO - llamafactory.hparams.parser - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: True, compute dtype: torch.float16\n",
      "07/02/2024 18:35:48 - WARNING - llamafactory.hparams.parser - We recommend enable `upcast_layernorm` in quantized training.\n",
      "07/02/2024 18:35:48 - WARNING - llamafactory.hparams.parser - `ddp_find_unused_parameters` needs to be set as False for LoRA in DDP training.\n",
      "07/02/2024 18:35:48 - INFO - llamafactory.hparams.parser - Process rank: 1, device: cuda:1, n_gpu: 1, distributed training: True, compute dtype: torch.float16\n",
      "[rank0]: Traceback (most recent call last):\n",
      "[rank0]:   File \"/nfs/scratch/umushtaq/am_work/LLaMA-Factory/src/llamafactory/launcher.py\", line 23, in <module>\n",
      "[rank0]:     launch()\n",
      "[rank0]:   File \"/nfs/scratch/umushtaq/am_work/LLaMA-Factory/src/llamafactory/launcher.py\", line 19, in launch\n",
      "[rank0]:     run_exp()\n",
      "[rank0]:   File \"/nfs/scratch/umushtaq/am_work/LLaMA-Factory/src/llamafactory/train/tuner.py\", line 50, in run_exp\n",
      "[rank0]:     run_sft(model_args, data_args, training_args, finetuning_args, generating_args, callbacks)\n",
      "[rank0]:   File \"/nfs/scratch/umushtaq/am_work/LLaMA-Factory/src/llamafactory/train/sft/workflow.py\", line 46, in run_sft\n",
      "[rank0]:     tokenizer_module = load_tokenizer(model_args)\n",
      "[rank0]:                        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/nfs/scratch/umushtaq/am_work/LLaMA-Factory/src/llamafactory/model/loader.py\", line 69, in load_tokenizer\n",
      "[rank0]:     tokenizer = AutoTokenizer.from_pretrained(\n",
      "[rank0]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py\", line 826, in from_pretrained\n",
      "[rank0]:     tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)\n",
      "[rank0]:                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py\", line 658, in get_tokenizer_config\n",
      "[rank0]:     resolved_config_file = cached_file(\n",
      "[rank0]:                            ^^^^^^^^^^^^\n",
      "[rank0]:   File \"/home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages/transformers/utils/hub.py\", line 402, in cached_file\n",
      "[rank0]:     resolved_file = hf_hub_download(\n",
      "[rank0]:                     ^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
      "[rank0]:     return fn(*args, **kwargs)\n",
      "[rank0]:            ^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1221, in hf_hub_download\n",
      "[rank0]:     return _hf_hub_download_to_cache_dir(\n",
      "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1335, in _hf_hub_download_to_cache_dir\n",
      "[rank0]:     os.makedirs(os.path.dirname(blob_path), exist_ok=True)\n",
      "[rank0]:   File \"<frozen os>\", line 215, in makedirs\n",
      "[rank0]:   File \"<frozen os>\", line 215, in makedirs\n",
      "[rank0]:   File \"<frozen os>\", line 225, in makedirs\n",
      "[rank0]: PermissionError: [Errno 13] Permission denied: '/blabla'\n",
      "[rank1]: Traceback (most recent call last):\n",
      "[rank1]:   File \"/nfs/scratch/umushtaq/am_work/LLaMA-Factory/src/llamafactory/launcher.py\", line 23, in <module>\n",
      "[rank1]:     launch()\n",
      "[rank1]:   File \"/nfs/scratch/umushtaq/am_work/LLaMA-Factory/src/llamafactory/launcher.py\", line 19, in launch\n",
      "[rank1]:     run_exp()\n",
      "[rank1]:   File \"/nfs/scratch/umushtaq/am_work/LLaMA-Factory/src/llamafactory/train/tuner.py\", line 50, in run_exp\n",
      "[rank1]:     run_sft(model_args, data_args, training_args, finetuning_args, generating_args, callbacks)\n",
      "[rank1]:   File \"/nfs/scratch/umushtaq/am_work/LLaMA-Factory/src/llamafactory/train/sft/workflow.py\", line 46, in run_sft\n",
      "[rank1]:     tokenizer_module = load_tokenizer(model_args)\n",
      "[rank1]:                        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank1]:   File \"/nfs/scratch/umushtaq/am_work/LLaMA-Factory/src/llamafactory/model/loader.py\", line 69, in load_tokenizer\n",
      "[rank1]:     tokenizer = AutoTokenizer.from_pretrained(\n",
      "[rank1]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank1]:   File \"/home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py\", line 826, in from_pretrained\n",
      "[rank1]:     tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)\n",
      "[rank1]:                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank1]:   File \"/home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py\", line 658, in get_tokenizer_config\n",
      "[rank1]:     resolved_config_file = cached_file(\n",
      "[rank1]:                            ^^^^^^^^^^^^\n",
      "[rank1]:   File \"/home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages/transformers/utils/hub.py\", line 402, in cached_file\n",
      "[rank1]:     resolved_file = hf_hub_download(\n",
      "[rank1]:                     ^^^^^^^^^^^^^^^^\n",
      "[rank1]:   File \"/home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
      "[rank1]:     return fn(*args, **kwargs)\n",
      "[rank1]:            ^^^^^^^^^^^^^^^^^^^\n",
      "[rank1]:   File \"/home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1221, in hf_hub_download\n",
      "[rank1]:     return _hf_hub_download_to_cache_dir(\n",
      "[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank1]:   File \"/home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1335, in _hf_hub_download_to_cache_dir\n",
      "[rank1]:     os.makedirs(os.path.dirname(blob_path), exist_ok=True)\n",
      "[rank1]:   File \"<frozen os>\", line 215, in makedirs\n",
      "[rank1]:   File \"<frozen os>\", line 215, in makedirs\n",
      "[rank1]:   File \"<frozen os>\", line 225, in makedirs\n",
      "[rank1]: PermissionError: [Errno 13] Permission denied: '/blabla'\n",
      "E0702 18:35:51.332000 140183078822400 torch/distributed/elastic/multiprocessing/api.py:826] failed (exitcode: 1) local_rank: 0 (pid: 2598635) of binary: /home/umushtaq/.conda/envs/notebook/bin/python\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/umushtaq/.conda/envs/notebook/bin/torchrun\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "             ^^^^^^\n",
      "  File \"/home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 347, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages/torch/distributed/run.py\", line 879, in main\n",
      "    run(args)\n",
      "  File \"/home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages/torch/distributed/run.py\", line 870, in run\n",
      "    elastic_launch(\n",
      "  File \"/home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages/torch/distributed/launcher/api.py\", line 132, in __call__\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/umushtaq/.conda/envs/notebook/lib/python3.11/site-packages/torch/distributed/launcher/api.py\", line 263, in launch_agent\n",
      "    raise ChildFailedError(\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n",
      "============================================================\n",
      "/nfs/scratch/umushtaq/am_work/LLaMA-Factory/src/llamafactory/launcher.py FAILED\n",
      "------------------------------------------------------------\n",
      "Failures:\n",
      "[1]:\n",
      "  time      : 2024-07-02_18:35:51\n",
      "  host      : node-1.hpc.cluster\n",
      "  rank      : 1 (local_rank: 1)\n",
      "  exitcode  : 1 (pid: 2598636)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "------------------------------------------------------------\n",
      "Root Cause (first observed failure):\n",
      "[0]:\n",
      "  time      : 2024-07-02_18:35:51\n",
      "  host      : node-1.hpc.cluster\n",
      "  rank      : 0 (local_rank: 0)\n",
      "  exitcode  : 1 (pid: 2598635)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "!llamafactory-cli train $train_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PVNaC-xS5N40"
   },
   "source": [
    "## Inference on the fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.listdir(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oh8H9A_25SF9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %cd /content/LLaMA-Factory/\n",
    "\n",
    "args = dict(\n",
    "  model_name_or_path=base_model, # use bnb-4bit-quantized Llama-3-8B-Instruct model\n",
    "  adapter_name_or_path=output_dir,            # load the saved LoRA adapters\n",
    "  template=\"llama3\",                     # same to the one in training\n",
    "  finetuning_type=\"lora\",                  # same to the one in training\n",
    "  quantization_bit=4,                    # load 4-bit quantized model\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = ChatModel(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(test_dataset_file, \"r+\") as fh:\n",
    "    test_dataset = json.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_prompts = []\n",
    "test_grounds = []\n",
    "\n",
    "for sample in test_dataset:\n",
    "    test_prompts.append(\"\\nUser:\" + sample[\"instruction\"] + sample[\"input\"])\n",
    "    test_grounds.append(sample[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_predictions = []\n",
    "\n",
    "for prompt in tqdm(test_prompts):\n",
    "\n",
    "    messages = []\n",
    "    messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "\n",
    "    response = \"\"\n",
    "    \n",
    "    for new_text in model.stream_chat(messages):\n",
    "        #print(new_text, end=\"\", flush=True)\n",
    "        response += new_text\n",
    "        #print()\n",
    "    test_predictions.append({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "    torch_gc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# next(model.engine.model.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# len(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(output_dir, f\"\"\"PE_ATC_results_{nb_epochs}.pickle\"\"\"), 'wb') as fh:\n",
    "    results_d = {\"ground_truths\": test_grounds,\n",
    "                 \"predictions\": test_predictions    \n",
    "        \n",
    "    }\n",
    "    pickle.dump(results_d, fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# import os\n",
    "# import pandas as pd\n",
    "# import json\n",
    "# import ast\n",
    "# from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'/Utilisateurs/umushtaq/models/PE_ATC_llama-3-8b-Instruct-bnb-4bit'\n",
    "# output_dir = 'models/PE_ATC_essay_llama-3-8b-Instruct-bnb-4bit'\n",
    "# nb_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(output_dir, f\"\"\"PE_ATC_results_{nb_epochs}.pickle\"\"\"), \"rb\") as fh:\n",
    "        \n",
    "        results = pickle.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grounds = results[\"ground_truths\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = results[\"predictions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grounds = [json.loads(x)[\"component_types\"] for x in grounds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [x[\"content\"] for x in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [json.loads(x)[\"component_types\"] for x in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opposite(component_type):\n",
    "\n",
    "    if component_type == \"Premise\":\n",
    "        return \"Claim\"\n",
    "    elif component_type == \"Claim\":\n",
    "        return \"Premise\"\n",
    "    elif component_type == \"MajorClaim\":\n",
    "        return \"Claim\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def harmonize_preds(grounds, preds):\n",
    "\n",
    "    l1, l2 = len(preds), len(grounds)\n",
    "    if l1 < l2:\n",
    "        diff = l2 - l1\n",
    "        preds = preds + [opposite(x) for x in grounds[l1:]]\n",
    "    else:\n",
    "        preds = preds[:l2]\n",
    "        \n",
    "    return preds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,(x,y) in enumerate(zip(grounds, preds)):\n",
    "    \n",
    "    if len(x) != len(y):\n",
    "        \n",
    "        preds[i] = harmonize_preds(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATC_preds = [item for row in preds for item in row]\n",
    "ATC_grounds = [item for row in grounds for item in row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check: \n",
    "len(ATC_preds) == len(ATC_grounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(ATC_grounds, ATC_preds, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"\"\"{output_dir}/classification_report.pickle\"\"\", 'wb') as fh:\n",
    "    \n",
    "    pickle.dump(classification_report(ATC_grounds, ATC_preds, output_dict=True), fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
